
## Nginx 고성능 부하분산

오늘날에는 높은 성능과 가용성이 필요하다, 이를 위해 같은 시스템을 여러개로 운영하고 부하를 각 시스템으로 분산한다.
 
`nginx`와 같은 프록시 또는 `로드 밸런서`서버는 업스트림 서버의 문제를 감지할 수 있어야 하며, 문제 발견 시 트래픽 전송을 중지할 수 있어야한다. 그렇지 않다면 사용자가 서버의 응답을 기다리다가 결국 타임아웃오류를 보게된다.

해당 문제를 찾기위해서 프록시 서버와 로드밸런서 서버가 업스트림 서버의 상태를 확인하도록 하는 방법이 있다.

`nginx` 에서는 `패시브 방식`을 제공하며 `nginx 플러스`에서는 추가로 `액티브 방식`을 제공한다.

> #### 액티브 방식
> - 로드 밸런서 장비가 스스로 업스트림 서버와 주기적으로 연결을 시도하거나 요청을 보내 서버 응답에 문제가 없는지 확인하는 방식.
>   업스트림 서버의 상태를 사용자 요청을 받기전에 미리 확인해야 할 때 유용하다
> 
> #### 패시브 방식
> 
>  - 사용자의 요청을 로드밸런서가 받은 시점에 업스트림 서버와의 연결이나 응답을 확인하는 방식, 업스트림 서버의 부하를 늘리지 않으면서 상태를 확인하려면
>    패시브 방식을 사용하는 편이 좋다.


## HTTP 부하분산, TCP 부하분산 

### 🌟 HTTP 부하분산
> HTTP부하 분산은 nginx의 upstream 블록과 http 모듈을 이용하여 서버간에 부하를 분산한다.

```shell
# 다음과 같이 설정하면 해당 위에 서버 2대를 통해 연결하며, 위 2대와 연결이 불가능할 경우 backup 서버를 사용한다.
# weight의 기본값은 1이며 해당 값을 생략할 수 있다, weight 1, 2를 다음과 같이주면 
# `test.sample.com`서버가 `10.10.10.10`서버에 비해 2배 많은 요청을 받는다.

upstream backend {
    server 10.10.10.10:80        weight=1;
    server test.sample.com:80    weight=2;
    server backup.sample.com:80  backup;
}

server {
    location / {
        proxy_pass http://backend;
    }
}
```

부하분산을 위한 목적지 정보는 유닉스 소켓, IP주소, DNS 혹은 다음 값들의 조합으로 구성한다.
해당 값들을 매개변수와 함께 지정하면 추가 제어방법을 제공한다. 매개변수들을 통해
분산 알고리즘에 가중치를 적용하거나 서버가 어떤 상태인지 알려주며, 서버 가용 여부를 판단하는 방법을 포함한다.

---

### 🌟 TCP 부하분산
> TCP 부하분산은 nginx의 upstream블록과 stream 모듈을 이용하여 TCP 서버간에 부하를 분산한다.

```shell

stream {
   
    # 3306 포트로 요청을 받아 읽기 전용 test1, test2로 구성된 MySQL서버로 부하를 분산한다.
    # HTTP 부하분산과 동일하게 2개의 MySQL서버가 다운되면 backup 서버로 요청을 전달한다.
    upstream mysql_read {
      server test1.sample.com:3306 weight=5
      server test2.sample.com:3306;
      server 10.10.10.10:3306 backup;      
    }
    
    server {
      listen 3306;
      proxy_pass mysql_read;
    } 
}
```

nginx 설치 후 특별한 설정파일을 수정하지 않았다면 기본 설정 파일 경로인 conf.d 폴더는 http블록에 포함된다. 
따라서 stream 모듈을 이용한 이 설정은 stream.conf.d 라는 별도의 폴더를 생성해 저장하는 편이 좋다.

```shell
# /etc/nginx 디렉터리 하위에 stream.conf.d 폴더 생성 후 mysql_read.conf 파일 생성.

# /etc/nginx/nginx.conf
# 하단 설정 추가. 
stream {
  include /etc/nginx/stream.conf.d/*/conf 
}

```

---

### 🌟 http vs stream

http와 stream의 가장 큰 차이점은 해당 두 모듈은 서로 다른 OSI 계층에서 동작한다.
 - http는 7계층인 애플리케이션 계층에서 동작하며 stream은 4게층은 전송계층에서 동작한다.
 - http모듈이 HTTP프로토콜을 완전히 이해하도록 특별히 설계된 반면 stream 모듈은 패킷의 전달 경로 결정과 부하분산에 더 중점을 두었다.


nginx에서 TCP 부하분산은 stream을 사용하지만 http모듈과 마찬가지로 stream모듈도 업스트림 서버 풀을 만들거나 개별 서버를 지정할 수 있다.

stream 모듈을 이용하는 경우 옵션을 통해 TCP 연결과 관계된 리버스 프록시의 여러 속성을 변경할 수 있다. 대표적인 속성으로는
SSL/TLS 인증서 제한, 타임아웃, 킵얼라이브 시간 설정 등이 있다. 일부 옵션은 nginx 변수를 값으로 사용할 수 있는데, 다운로드 속도 제한이나
SSL/TLS 인증서 유효성 검사에서 사용할 이름이 지정된 변수 혹은 이 변수가 포함된 값을 옵션에 사요할 수 있다.

---

### 🌟 UDP 부하분산

> udp 로 정의된 upstream 블록은 nginx stream모듈에서 사용하여 UDP 서버간에 부하 분산을 한다.

```shell
stream {
  
  upstream ntp {
   server ntp1.sample.com:123 weight=1;
   server ntp2.sample.com:123; 
  }
 
 server {
   listen 123 udp;
   proxy_pass ntp;
 } 
}
```

UDP 부하분산은 위에 보았던 TCP 부하분산과 비슷하며 listen 옵션에 `udp`만 추가하면 된다.

UDP와 TCP차이는 listen 지시자를 통해 UDP 데이터그램을 처리할 소켓을 지정한다. 해당 데이터그램을
다루기 위해서는 TCP에서 사용하지 않는 지시자를 몇가지 사용한다. 
대표적으로는 `proxy_response` 지시자를 사용, 해당 지시자를 설정하지 않으면 `proxy_timeout` 지시자의 제한값이 되기 전까지 무제한으로 응답을 처리한다.

* `proxy_timeout`은 연결을 닫기 전에 목적지 서버로의 읽기, 쓰기 작업완료를 기다리는 시간을 지정하는데 사용한다.

---

### 🌟 부하분산 알고리즘

nginx 에서 제공하는 부하분산 알고리즘에는 다음 종류가 있다.
 - 리스트 커넥션
 - 리스트 타임
 - 제네릭 해시
 - 랜덤
 - IP 해시 등등 

`제네릭 해시` , `랜덤`, `리스트 타임`을 제외한 모든 부하분산 알고리즘은 리스트 커넥션 알고리즘과 
마찬가지로 단독으로 사용한다. 위에서 나와있는 부하분산 알고리즘은 HTTP, TCP, UDP 업스트림 풀에 사용할 수 있다.


### 🌱 라운드 로빈
> nginx의 기본값으로 설정된 부하분산 방식이다. 업스트림 풀에 지정된 서버의 순서에 따라 요청을 분산한다. 
> 가중치를 적용하면 더 높은 가중치를 가진서버가 더 많은 요청을 받는다. 해당 가중치는 평균의 통계적 확률에 다라 계산된다.


### 🌱 리스트 커넥션(least_time)
> nginx와의 연결 수가 가장 적은 업스트림 서버로 요청을 전달해 부하 분산한다.
> 라운드로빈과 마찬가지로 가중치를 기반으로 요청을 어떤 서버로 보낼지 계산한다. 

### 🌱 리스트 타임(least_time) - nginx plus
> nginx 플러스에서만 사용할 수 있는 방법이다. <br>
> 리스트 커넥션과 마찬가지로 연결 수가 가장 적은 업스트림 서버로 요청을 전달하지만 그중 응답 시간이 가장 빠른 서버를 우선시 한다는 차이가 있다. <br>
> 가장 복잡한 부하분산 알고리즘으로 높은 성능이 필요한 웹 애플리케이션에 적합하다. <br><br>
> 업스트림 서버가 처리하는 요청수가 적다고 해서 늘 가장 빠른응답시간을 보장하지 않는다. 리스트커넥션방식에 대한 일종의 부가 기능으로 생각할 수 있다.
> 
> 해당 알고리즘을 사용할 때는 요청 처리 시간의 분산을 고려해야한다.<br>
> 애초부터 처리 시간이 긴 요청이 있따면 요청 처리 시간 통계의 범위가 넓어지며, 처리 시간이 길어도 항상 
> 서버 성능이 낮거나 과부하가 걸린것은 아니다.
> 
> 따라서 많은 처리가 필요한 요청은 부하분산 알고리즘을 고민하기전에 비동기로 처리하는 편이 나을 수 있다.
> 
> 리스트 타임 알고리즘을 사용할때는 `header` or `last_byte`매개변수 중 하나를 지정한다.
>  
> `header` : 업스트림 서버로부터 응답 헤더를 받을 때까지 소요된 시간을 사용한다.<br>
> `last_byte` : 헤더뿐 아니라 응답 전체를 받을 때 까지 소요된 시간을 사용한다.

### 🌱 제네릭 해시(hash)
> 서버 운영자는 주어진 텍스트 문자열 혹은 요청이나 런타임의 변수를 사용해 해시를 정의한다.<br>
> nginx는 수신한 요청의 해시를 생성하고 업스트림 서버 선택에 활용해 부하를 분산한다.
> 
> 제네릭 해시는 요청을 처리할 서버를 선택하는 데 깊이 개입해야 할때나 캐시가 있을 확률이 농픈 서버로 요청을 전달하고 싶을때 유용하다.
> 다만 서버가 업스트림 풀에서 추가되거나 삭제되면 해시처리된 요청이 재분배된다는 점을 주의해야한다.
> 
> `consistent` 을 사용하면 재분배의 영향을 최소화할 수 있다.

### 🌱 랜덤(random)
> nginx가 업스트림 풀에 지정된 서버를 임의로 선택해 요청을 전달하며 이때 업스트림 서버에 지정된 가중치를 고려한다.
> 매개변수로 two [method] 를 사용하면 먼저 서버 두대를 임의로 선택하고 method 에 지정된 알고리즘을 이용해 2차 부하분산을 한다.
> 만약 method를 생략하면 기본 알고리즘은 `least_conn`입니다.

### 🌱 IP 해시(ip_hash)
> HTTP에 대해서만 동작하는 방법이다. <br>
> IP주소를 이용해 해시를 생성한다. 원격 변수를 사용하는 `제네릭 해시`와 달리 IPv4 체계의 옥텟값 중 처음 세값 혹은 IPv6주소전체를 
> 해시에 사용한다. 
> 
> 이 방식을 통해 업스트림서버에 문제가 없는 한 같은 서버로 할당된다. 이러한 동작 특성은 세션 상태가 중요하며,
> 이 정보가 애플리케이션의 공유 메모리를 통해 공유되지 않은 경우 유용하다.

----------

### 엔진엑스 플러스 제공 기능

### 🌱 스티키 쿠키(sticky cookie)
> `스티키 쿠키`를 사용하면 사용자가 지속적으로 특정 업스트림 서버에 연결되도록 쿠키를 생성해 추적한다.

### 🌱 스티키 런(sticky learn)
> 업스트림 애플리케이션이 생성한 쿠키를 찾아내어 추적한다.

### 🌱 스티키 라우팅(sticky route)
> 사용자의 요청을 처음 받은 서버에 대해 그 사용자의 후속 요청이 모두 전송되는 기술


### 🌱 커넥션 드레이닝
> drain 매개변수를 설정하면, 엔진엑스가 추적중이 아닌 새로운 연결을 더이상 업스트림 서버로 보내지 않도록 한다.<br>
> (drain을 설정하면 더는 새로운 세션을 만들지 않는다.)
> 다만 이미 연결되있는 세션은 유효기간 동안 유지가 된다.

----------


### 🌱 수동적인 헬스 체크  

nginx 부하분산 설정에 health check 매개변수를 사용하면 수동적인 헬스체크가 가능하다.

해당 설정으 ㄴ사용자 욫어에 대한 업스트림 서버의 응답을 모니터링해 업스트림 서버의 상태를 수동으로 확인한다.

`max_faile`는 최대 실패 횟수이며 `fail_timeout`은 실패에 대한 타임아웃 값을 설정 할 수 있다.

(사용자 요청이 들어오기 전에 선제적으로 상태 확인을 하지 않는다는 의미일뿐)

----------

### 🌱 능동적인 헬스 체크 (엔진엑스 플러스)

설정 파일의 location 블록에 health_check 지시자를 사용하여 능동적으로 상태 확인 가능.
해당 설정된 내용으로 interval옵션에 설정된 초마다 헬스체크를 한다.

### 🌱 슬로 스타트 (엔진엑스 플러스)

점진적으로 사용자 연결을 늘려나가게 하는 옵션

`slow_start` 에 설정된 시간을 기준으로 점진적으로 연결 수를 천천히 늘려가게 하는 옵션