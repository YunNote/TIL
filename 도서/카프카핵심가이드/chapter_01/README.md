
# 1. 카프카 시작하기

---

## 발행/구독 메시지 전달
> 발행/구독 메시지 전달 패턴의 특징은 전송자가 데이터를 보낼 때 직접 수신자로 보내지 않는다는 것이다. <br>
> 대신 전송자는 어떤 형태로든 메시지를 분류해서 보내고, 수신자는 이렇게 분류된 메시지를 수신하게 된다.
> 
> 발행/구독 시스템에는 대게 발행된 메시지를 전달받고 중계해주는 중간 지점 역할을 하는 브로커가 있다.


---

### 초기의 발행/구독 시스템

발행/구독 패턴은 초기에는 데이터가 필요한 하나의 서버에 데이터를 전송하여 하나의 애플리케이션 서버에서 해당 데이터를 기준으로
동작하게 만들었다. 하지만 시간이 지나면서 서비스는 커지게 되고 다양한 목적으로 데이트럴 활용하는 많은 애플리케이션들이
추가될 수 있다. 결과적으로는 아래 이미지 처럼 구성하게 된다.

![img.png](img.png)

딱봐도 해당 방식은 개선할 필요가 있다고 보여진다.

다음과 같은 방법을 해결하기 위해 나온것이 해당 값을 관리하는 하나의 애플리케이션 서버를 제공하고, 해당 애플리케이션 서버로
값들이 필요로하는 어떤 시스템이든 질의를 할 수 있도록 해주는 것이다.


![img_1.png](img_1.png)

---

### 개별 메시지 큐 시스템 

위에 나온 구조 외에도 `로그 메시지에 대한 발행/구독`, `사용자 추적 발행/구독`에 대한 내용이 추가 되어야 한다면
아래와 같은 시스템 구성이 나오게 된다.

![img_2.png](img_2.png)

위 사진을 보면 비지니스가 확장됨에 따라 `지표값 발행/구독`, `로그 메시지 발행/구독`, `사용자 추적 발행/구독`와 같이 
발행/구독 서버가 늘어나면서 관리포인트가 늘어나게 되고, 데이터를 전달하기 위해 중복코드가 발생하며, 버그가 발생하게 된다면
다수의 큐에 대한 시스템 관리가 이뤄져야 한다.

이러한 문제를 해결하기 위해서는 중앙에서 데이터의 발행/구독을 처리하는 중앙 집중화된 시스템이 필요 하게 된다.

---

## 카프카 

> 카프카는 위에서 나온 문제를 해결하기 위해 고안된 발행/구독 시스템이다.<br>
> 카프카는 `분산 커밋 로그` or `분산 스트리밍 플랫폼` 이라고도 불린다.<br>
> 
> 카프카는 파일시스템이나 데이터베이스 처럼 모든 트랜잭션 기록을 지속성있게 보존함으로써 일관성있게 복구할 수 있도록 보관하며, 확장시
> 성능을 향상시키고 실패가 발생하더라도 데이터 사용에는 문제가 없도록 시스템 안에서 분산시켜 저장할 수 있다


### 메시지와 배치

카프카에서 데이터의 기본 단위는 `메시지`이다. 우리가 흔하게 사용하는 데이터베이스의 `row` or `레코드`와 비슷하다고 볼 수 있다.

`메시지` 
 - 단순히 바이트의 배열이기 때문에 특정한 형식이나 의미가 없다.

`키`
 - 메타 데이터를 포함할 수 있다. 키역시 특별한 의미가 없는 단순한 바이트의 배열이다.
 - 메시지를 저장할 파티션을 결정하기 위해 사용된다. 간단한 방법으로는 키 값에서 해시값을 생성한 뒤 이 값을 토픽의 파티션 수로 나눴을떄 나오는 나머지 값에 해당하는 파티션에 메시지를 저장하게 된다. 이러면 같은 키값을 갖는 메시지들은 파티션의 갯수가 변경되지 않는한 항상 같은 파티션에 저장된다.

카프카는 효율성을 위해 메시지를 `배치` 단위로 저장한다. 
배치는 그냥 같은 토픽의 파티션에 쓰여지는 메시지들의 집합일 뿐이다. 

메시지를 쓸때마다 네트워크 신호가 오가는 것은 막대한 오버헤드를 발생하게 된다. 따라서 메시지를 배치 단위로 모아서
쓰면 오버헤드를 줄일 수 있다. 

물론 이것은 지연과 처리량사이에 트레이드 오프를 발생시킨다. 이말은 즉 배치 크기가 커질수록 시간당
처리되는 메시지의 수는 늘어나겠지만, 메시지가 전달되는데 걸리는 시간은 늘어나게 된다.

배치는 이러한 경우때문에 더 효율적인 데이터 전송과 저장을 위해 약간의 처리능력을 들여서 압축되는 경우가 많다.

---


### 스키마

카프카는 단순한 바이트 배열일 뿐이지만 전달하는 내용을 이해하기 쉽도록 일정훈 구조를 부여하는 것이 권장된다. 이것을 스키마라고 한다.

각 애플리케이션의 필요에 따라 사용 가능한 스키마가 여러가지가 있다. `JSON`, `XML` 이 기본적으로 많이 사용되나 해당 방식들은
버전간의 호환성 유지 기능이 떨어진다.

많은 카프카 개발자들은 아파치 `에이브로(Avro)` 를 선호한다. 

- 조밀한 직렬화 형식을 제공한다.
- 메시지 보넻와 스키마를 분리하기 때문에 스키마가 변경되더라도 코드를 생성할 필요가 없다.
- 강력한 데이터 타이핑과 스키마 변경에 따른 상위 호환성, 하위호환성을 지원한다.

카프카는 일관적인 데이터 형식이 중요하다. 이유는 메시지쓰기와 읽기 작업을 분리할 수 있도록 해주기 때문이다.
만약 해당 작업들이 결합되어있다면 메시지를 구독하는 애플리케이션들먼저 구버전과, 신버전 형식을 동시에
함께 지원할 수 있도록 업데이트 되어야 하며, 그다음에 메시지를 발행하는 애플리케이션이 신버전 형식을
사용하도록 업데이트 될 수 있을것이다.

잘 정의된 스키마를 공유 저장소에 등록함으로써 카프카는 구,신 버전을 동시에 지원하도록 하는 작업 없이도 메시지를 처리할 수 있다.

---

### 토픽과 파티션 

`토픽` 이란 저장되는 메시지를 의미하며 `토픽` 단위로 분류된다. 

`토픽`은 우리가 가장 많이 알고 있는 데이터베이스의 테이블이나, 파일 시스템의 폴더와 비슷하다.

토픽은 다시 여러개의 파티션으로 나뉘어 진다. 커밋로그의 관점에서는 파티션은 하나의 로그에 해당한다. 파티션에 메시지가 쓰여질 때는 
추가만 가능한 형태로 쓰여지며, 읽을 떄는 맨 앞부터 제일 끝까지의, 순서로 읽힌다.  

다만 토픽에 여러개의 파티션이 있는 만큼 토픽 안의 메시지 전체에 대해 순서는 보장되자 않으며, 단일 파티션 내부에서 만 순서가 보장된다.

파티션의 장점은 카프카 `데이터 중복`과 `확장성`을 제공하는 것이다.

`확장성` - 각 파티션이 서로 다른 서버에 저장될 수 있어 하나의 토픽이 여러개의 서버로 수평적으로 확장되어 하나의 서버의 용량을 넘어가는 
성능을 보여줄 수 있다.

`데이터 중복` - 파티션이 복제될 수 있어 다른 서버들이 동일한 파티션의 복제본을 저장하고 있어. 서버중 하나에 장애가 발생하더라도
읽거나 쓸 수 없는 상황이 벌어지지 않는다.


카프카와 같은 시스템을 사용하면 스트림이라는 용어가 등장하게 된다, 스트림은 파티션의 갯수와 상관없이 하나의 토픽에 저장된
데이터로 간주되며, 프로듀서로부터 컨슈머로의 하나의 데이터 흐름을 나타낸다.

---

## 프로듀서와 컨슈머

카프카에는 기본적으로 `프로듀서`와 `컨슈머` 두 종류가 있다. 프로듀서와 컨슈머릴 기본 요소로 사용하며 좀 더 고차원적인 기능을 제공하는
`카프카 커넥트 API` 와 `카프카 스트림`도 있다.

---

### 프로듀서
> 프로듀서는 새로운 메시지를 생성합니다. 다른 시스템에서는 `발행자` or `작성자`라고도 부르기도 한다.<br>
> 메시지는 특별한 토픽에 쓰여지며 기본적으로 프로듀서는 메시지를 쓸 때 토픽에 속한 파티션 사이에 고르게 나눠쓰도록 되어 있다.<br>
> 하지만 항상 나눠쓰는것이 아니라 특별한경우에는 특정한 파티션을 지정해서 쓰기도 한다.<br>
> 바로 `키`를 이용하면 해당 `키`의 해시를 특정 파티션으로 대응시켜주는 `파티셔너`를 사용하여 구현하게 되면 동일한 키를 가진
> 메시지들은 같은 파티션에 저장하게 된다.

---

### 컨슈머
> 컨슈머는 메시지를 읽는다. 다른 시스템에서는 `구독자` or `독자`라고 부르기도 한다<br>
> 컨슈머는 1개 이상의 토픽을 구독해서 저장된 메시지들을 각 파티션에 쓰여진 순서대로 읽어온다.<br>
> 메시지는 오프셋을 기록함으로써 어느 메시지까지 읽었는지를 유지한다.

`오프셋` - 오프셋은 지속적으로 증가하는 정수값이며, 메시지를 저장할 때 메시지에 부여하는 메타데이터이다. 
뒤에 오는 오프셋값은 앞선 메시지보다 큰 오프셋을 갖는다. 이와같은 오프셋을 기반으로 컨슈머가 작업을 멈췄다가 다시 시작하더라도
마지막으로 읽었던 메시지의 바로 다음부터 읽을 수 있다.

`컨슈머 그룹` - 컨슈머는 `컨슈머그룹`의 일원으로 동작한다. 컨슈머 그룹은 토픽에 저장된 데이터를 읽어오기 위해 하나 이상의 컨슈머로 이뤄져 있다.
`컨슈머 그룹`은 각 파티션이 하나의 컨슈머에 의해서만 읽는다. 컨슈머와 파티션의 대응관계는 소유권이라고도 부른다.

해당 방식을 사용함으로써 대량의 메시지를 갖는 토픽들을 읽기 위해 컨슈머들을 수평 확장할 수 있고, 컨슈머 그룹중 특정
컨슈머가 장애가 발생하더로다, 다른 컨슈머들이 장애가 발생한 컨슈머가 읽고 있던 파티션을 재할당 받아 이어서 작업한다.

---

## 브로커와 클러스터

### 브로커 
> 하나의 카프카 서버를 `브로커`라고 부른다. <br>
> 프로듀서로부터 메시지를 전달받아 오프셋을 할당한다음 저장소에 쓴다. <br>
> 브로커는 컨슈머의 파티션 읽기 요청을 처리하고 발행된 메시지를 보낸다. 하드웨어의 성능에 따라 다르겠지만 브로커는
> 초당 수천 개의 파티션과 수백만 개의 메시지를 쉽게 처리한다.

브로커는 `클러스터`의 일부로서 작동하도록 설계되었다. 하나의 클러스터에는 여러개의 브로커가 포함될 수 있고,
그중하나의 브로커가 클러스터 컨트롤러의 역할을 한다. (클러스터 컨트롤러는 포함된 브로커중 하나가 자동으로 선정된다.)

`컨트롤러`는 파티션을 브로커에 할당해주거나 장애가 발생한 브로커를 모니터링 해주는 등의 관리 기능들을 담당한다.
파티션은 클러스터 안의 브로커 중 하나가 담당하며 해당 브로커를 `파티션 리더`라고 부른다. 또한 복제된 파티션이
여러 브로커에 할당될 수 있는데 이것들은 `팔로워`라고 부른다. 

`복제` - 복제 기능은 메시지를 각 파티션에 중복 저장함으로써 리더 브로커가 장애가 발생하더라도 팔로워중 하나가 리더 역할을 이어받을 수 있다.
 또한, 데이터가 중복 저장되어있기 때문에 프로듀서들은 리더 브로커에게 메시지를 발행해야하지만. 읽어들이는
컨슈머들은 리더나 팔로워중 하나로부터 데이터를 읽어와도 된다.

`보존` - 브로커는 토픽에 대해서 기본적인 보존 설정이 되어있다. 특정 기간동안 해당 메시지들을 저장해주거나, 파티션의 크기가
일정 크기에 도달할때까지 데이터를 보존하며, 한도값에 도달하면 메시지는 만료하여 삭제하게 된다. 

해당 설정을 통해 사용 가능한 최소한의데이터 양을 정의한다. 설정은 각각의 토픽에 메시지가 필요한 정도까지만 저장되도록 설정을 잡아줄 수 있다.

---

## 다중 클러스터 

다중클러스터를 운용하게되면 `데이터 유형별 분리`, `보안 요구사항을 축족시키기 위한 격리` , `재해복구를 대비한 다중 데이터센터` 와 같은 
장점이 있다. 

다중 클로스터를 활용한다면 해당 메시지를 클러스터에 복제해 줄 필요가 있다. 카프카는 데이터를 다른 클러스터로
복제하는데 사용되는 `미러메이커`라는 툴을 포함한다.

`미러 메이커` 또한 근본적으로는 큐로 연결된 카프카 컨슈머와 프로듀서에 불과하다. 

---

## 왜 카프카를 쓸까 ?

### 다중 프로듀서
> 카프카는 여러 프로듀서를 처리할 수 있다. 클라이언트가 여러 토픽을 사용하던, 하나를 사용하던 상관없다.
> 
> 이러한 이유로 데이터를 수집하고 일관성을 유지하는데 적격이다. 다수의 마이크로서비스를 통해 사용자에게 공통의 형식으로 제공할때
> 컨슈머 애플리케이션은 여러개의 토픽에서 데이터를 읽을 필요 없이, 하나의 뷰 스트림만 읽어오면 된다.


### 다중 컨슈머

> 다중 프로듀서와 함께 컨슈머는 상호 간섭 없이 메시지 스트림을 일도록 설계되었으며, 해당 내용이 다른 큐 시스템과의 차이점이기도 하다.
> 
> 카프카 컨슈머는 컨슈머그룹의 일원으로 작동함으로써 하나의 스트림을 여럿이서 나눠 읽을 수 있다. 따라서 메시지는 컨슈머 그룹에 대해 한번만 처리된다.


### 디스크 기반 보존

> 카프카는 메시지를 지속성 있게 저장할 수도 있다. 이말은 항상 실시간으로 데이터를 읽어올 필요는 없다는것이기도 하다.
> 
> 카프카에서 메시지는 디스크에 쓰여진뒤 설정된 보존 규칙과 함께 저장된다. 해당 보존 규칙은 토픽별로 설정이 가능하여 
> 서로 다른 메시지 스트림이 컨슈머에 필요에 따라 다른 기간동안 보존되기도 한다. 따라서 컨슈머가
> 느린 처리 속도 혹은 트래픽 폭주로 인해서 뒤쳐저도 유실의 위험은 없다. 
> 
> 이러한 장점때문에 컨슈머가 내려가도라도 다시 시작되면 작업을 멈춘 지점에서부터 유실 없이 데이터를 처리할 수 있다.

### 확장성
> 카프카는 유연한 확장성을 가지고 있어 어떠한 크기의 데이터도 쉽게 처리 가능하다.
> 
> 처음에는 하나의 브로커로 시작, 3개의 브로커가 하나로 구성된 클러스터 구성, 마지막에는 데이터 증가에 따라 수십개에서 수백개의 브로커로
> 구성된 대규모 클러스터로 이뤄진 환경으로 작업하면 된다. 
> 
> 카프카 클러스트는 동작중에도 전체 가용성에 영향을 주지않으면서 확장이 가능하다. 이말은 개별 브로커의 장애를 
> 처리하면서도 지속적으로 클라이언트이ㅡ 요청을 처리할 수 있따는것을 의미한다. 


### 고성능 
> 아파치 카프카가 고부하에서도 높은 성능을 보여주는 이유는 위와같은 장점들 때문이다. 
> 
> 발행된 메시지가 1초도 안걸리면서도 프로듀서, 컨슈머, 브로커 모두가 매우 큰 메시지 스트림을 쉽게 다룰 수 있도록 수평적으로 확장될수 있다는 점이다.

### 플랫폼 기능
> 카프카 코어 프로젝트에는 개발자들이 자주 하는 작업을 쉽게 할 수 있도록 지원하는 플랫폼 기능이 추가 되었다.
> 
> 이 기능들은 탄탄한 기반과 자유로운 형태로 실행할 수 있는 유연성을 갖춘 API 라이브러리의 형태로 사용이 가능하도록 제공된다.
> 
> `카프카 커넥트`는 시스템으로부터 데이터를 가져오거나 데이터를 싱크 시스템으로 내보내는 작업을 도와준다.(9장)
> 
> `카프카 스트림즈`는 가변성과, 내고장성을 갖춘 스트림 처리 애플리케이션을 쉽게 개발할 수 있게 해준다. 상세한 설명은 뒤에서 다룬다 (14장)

---


## 