# 웹 로봇

---

`웹로봇`은 사람과의 상호작용 없이 연속된 웹 트랜잭션들을 자동으로 수행하는 소프트웨어 프로그램을 뜻한다.

이 웹로봇들은 웹사이트에 다른 웹사이트로 하이퍼링크, 콘텐츠를 따라 이동하면서 발견한 데이터를 처리한다.
우리는 이를 흔히 `크롤러`, `스파이더`, `웜`, `봇`이라고 부르 기도 한다.

---

## 웹 로봇의 예

- 주식시장 서버에 매 분 HTTP GET요청을 보내고, 얻은데이터를 활용하여 주가 추이 그래프를 생성하는 주식 그래프 로봇
- 월드 와이드 웹의 규모와 진화에 대한 통겨정보를 수집하는 웹 통계 조사 로봇, 이것들은 웹을 떠돌면서 페이지의 갯수를 세고 각 페이지의 크기, 언어, 미디어를 기록 
- 검색 데이터베이스를 만들기위해 발견한 모든 문서를 수집하는 검색엔진 봇 
- 상품에 대한 가격 정보를 수집하는 가격 비교 로봇


---

## 크롤러와 크롤링


> `웹 크롤러`는 웬페이지 한개를 호출하고 그 다음 그페이지가 가리키는 모든 웹페이지를 가져와, 계속해서 그다음 페이지딜이 가리키는
> 모든 웹페이지들을 가져온다. 재귀적인 방식으로 순회하는 로봇을 웹 크롤러라고 부른다. 
> 
> 이러한 로봇을 크롤러 혹인 스파이더라고 부른다.

인터넷 검색엔진은 웹을 돌아다니면서 그들이 만나는 모든 문서를 끌어오기 위해 웹 크롤러를 사용한다. 해당 문서들은
나중에 처리되어 검색 가능한 데이터베이스로 만들어져 사용자들이 특정 단어를 포함한 문서를 찾을 수 있게 해준다.

---

### 어디에서 시작하는가: '루트 집합'

크롤러를 시작하기전 어디서부터 시작할지 출발지점을 알려줘야 한다. 이때 크롤러가 방문을 시작하는 URL들의
초기 집합을 루트집합이라고 부른다. 

루트집합을 고를때는 모든 링크를 크롤링 할 수 있도록관심있는 웹페이지들의 대부분을 가져 올수 있도록 충분히 다른 장소에서 URL들을 선택해야한다.

루트집합을 통해 페이지를 돌며 검색하던중 몇몇 웹페이지들은 어떤 링크도 없이 오도가도 못하게 거의 고립되어 있는 경우가 생긴다
이런 경우때문에 대규모 크롤러 제품들은 루트 집합에 새 페이지나 알려지지 않은 페이지들을 추가하는 기능들을 제공한다.

---

### 링크 추출과 상대 링크 정상화 

크롤러는 웹을 돌아다니면서 꾸준히 문서를 검색한다음 각 페이지안에 들어있는 URL링크들을 파싱해서 크롤링할 페이지들의
목록에 추가해야한다.

새 링크를 발견하면 보통 급속히 확장되게 된다. 크롤러들은 간단한 HTML 파싱을해서 링크들을 추출하고 상대 링크를
절대링크로 변환할 필요가 있다.

---

### 순환 피하기

크롤링을 할때 가장 주의해야할 점은 루프나, 순환에 빠지지 않도록 매우 조심해야한다.
P249 에서 제공하는 이미지를 보면 서로 링크된 페이지가 순환이 되며 동일한 페이지를 계속 가져오게 되는 순환에 빠진다
따라서 이 문제를 해결하기 위해서는 방문한 링크에 대해서 알 고 있어야 한다.

---

### 루프와 중복

순환은 최소 다음의 세가지 이유로 인해 크롤러에게 해롭다.

1. 같은 페이지들을 반복해서 가져오기때문에 시간을 낭비하게 되며, 이러한 크롤러가 네트워크 대역폭을 다 차지하고 어떠한 페이지도 가져올 수 없게 되어버릴 수 있다.
2. 크롤러가 같은 페이지를 반복해서 가져오게 되면 웹 서버의 부담이 된다. 만약 크롤러의 네트워크 접근 속도가 충분히 빠르다면, 웹사이트에게 부하가 가해져 실제 사용자도 사이트에 접근할 수 없게 막아버리게 될 수 있다. 따라서 이러한 행위가 법적인 문제제기의 근거가 될 수 있다.
3. 수많은 중복페이지를 가져오게 되고, 크롤러의 애플리케이션은 중복된 컨텐츠로 넘쳐나게 된다.

---

### 빵 부스러기의 흔적 

방문한 사이트를 지속적으로 추적하는 것은 쉽지 않다, 지금 순간에도 동적으로 생성된 콘텐츠를 제외하더라도 수십억 개의 
서로 다른 웹페이지들이 존재한다.

대규모 웹 크롤러가 그들이 방문한 곳을 관리하기 위해 사용하는 기법은 다음과 같다.

#### 트리와 해시 테이블
> 복잡한 로봇이라면 방문한 URl을 추적하기 위해 검색트리나 해시테이블을 사용할 수 있다. 해당 자료구조는 URL을 훨씬 빨리 찾아볼 수 있게 해준다.

#### 느슨한 존재 비트맵
> 공간 사용을 최소화하기 위해 존재비트배열과 같은 느슨한 자료구조를 사용한다. 각 URL은 함수에 의해 고정된 크기의 숫자로 변환되고
> 배열 안에 대응하는 존재비트를 갖는다. 크롤링이 되었을때 해당하는 존재비트가 만들어지고 만약 존재비트가 이미 존재한다면 그 URL을 이미 크롤링 되었다고 간주한다.


#### 체크 포인트
> 방문한 URL의 목록이 디스크에 저장되었는지 확인한다.

#### 파티셔닝 
>한대의 컴퓨터에서 하나의 로봇이 크롤링을 완수하는 것은 불가능할정도로 웹이 성장하였다. 따라서 여러개의 분리된 크롤링봇으로 
> URL들의 특정한 부분을 할당하여 책임을 진다, 개별 로봇들은 URL들을 넘겨주거나, 오동작하는 동료를 도와주거나
> 그 외의 이유로 활동을 조정하기 위해 커뮤니케이션을 한다.

---

### 별칭과 로봇 순환 